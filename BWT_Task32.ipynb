{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f95635c2",
   "metadata": {},
   "source": [
    "# BWT - Deep Learning Track\n",
    "## Task#32: Building Hybrid Networks using CNN and LSTM\n",
    "### Adil Mubashir Chaudhry\n",
    "\n",
    "#### What are hybrid models?\n",
    "\n",
    "Hybrid models, in the context of machine learning, refer to models that combine different types of neural network architectures or machine learning algorithms to leverage the strengths of each component. These models integrate multiple building blocks to achieve better performance or handle complex tasks that may require different approaches.\n",
    "\n",
    "There are several types of hybrid models, and the choice of architecture depends on the specific problem and the combination of techniques being used. Here are a few common types of hybrid models:\n",
    "\n",
    "__CNN-RNN Hybrid Model__\n",
    "\n",
    "Combines Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs).\n",
    "CNNs are excellent for capturing spatial information in images, while RNNs handle sequential or temporal information.\n",
    "Commonly used for tasks like image captioning, video classification, and activity recognition.\n",
    "\n",
    "\n",
    "Below in the 2 cells we can use the hybrid models to perform both sentiment analysis and image recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b2971c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 32s 38ms/step - loss: 0.3953 - accuracy: 0.8150 - val_loss: 0.3306 - val_accuracy: 0.8551\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 31s 39ms/step - loss: 0.2229 - accuracy: 0.9129 - val_loss: 0.4261 - val_accuracy: 0.8247\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 35s 45ms/step - loss: 0.1158 - accuracy: 0.9601 - val_loss: 0.4988 - val_accuracy: 0.8408\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.4988 - accuracy: 0.8408\n",
      "Test Loss: 0.4988\n",
      "Test Accuracy: 0.8408\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Conv1D, MaxPooling1D, LSTM\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.datasets import imdb\n",
    "\n",
    "max_features = 10000  # Maximum number of words in the vocabulary\n",
    "max_len = 100  # Maximum length of input sequences\n",
    "embedding_dim = 100  # Dimensionality of word embeddings\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dim, input_length=max_len))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=3, validation_data=(x_test, y_test))\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ed10519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 22s 0us/step\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 44s 53ms/step - loss: 1.3691 - accuracy: 0.5063 - val_loss: 1.1448 - val_accuracy: 0.5921\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 41s 53ms/step - loss: 0.9935 - accuracy: 0.6506 - val_loss: 0.9368 - val_accuracy: 0.6680\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 40s 51ms/step - loss: 0.8292 - accuracy: 0.7095 - val_loss: 0.8804 - val_accuracy: 0.6909\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 40s 51ms/step - loss: 0.6953 - accuracy: 0.7578 - val_loss: 0.8438 - val_accuracy: 0.7050\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 41s 52ms/step - loss: 0.5708 - accuracy: 0.8041 - val_loss: 0.8333 - val_accuracy: 0.7111\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 40s 51ms/step - loss: 0.4365 - accuracy: 0.8553 - val_loss: 0.8246 - val_accuracy: 0.7259\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 40s 51ms/step - loss: 0.3149 - accuracy: 0.8994 - val_loss: 0.8798 - val_accuracy: 0.7177\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 41s 52ms/step - loss: 0.2082 - accuracy: 0.9412 - val_loss: 0.9234 - val_accuracy: 0.7225\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 41s 53ms/step - loss: 0.1244 - accuracy: 0.9709 - val_loss: 0.9891 - val_accuracy: 0.7165\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 41s 53ms/step - loss: 0.0745 - accuracy: 0.9862 - val_loss: 1.0341 - val_accuracy: 0.7133\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0341 - accuracy: 0.7133\n",
      "Test Loss: 1.0341\n",
      "Test Accuracy: 0.7133\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, LSTM, Reshape\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Reshape((1, -1)))  # Reshape the feature vector to match LSTM input\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
